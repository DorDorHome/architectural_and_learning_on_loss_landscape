# LLA suite config for ResNet18 backbone on CIFAR-10
runs: 1
run_id: 0
seed: 123

# Device and basic training for short fine-tune
device: 'cuda:0'
epochs: 0            # No training by default; we only save an initial checkpoint
batch_size: 128
num_workers: 4

use_wandb: false
use_json: true

# Data settings
data:
  dataset: 'CIFAR10'
  use_torchvision: true
  data_path: '/hdda/datasets'
  num_classes: 10

# Model: switch to ResNet
net:
  type: 'resnet_custom'
  network_class: 'conv'
  device: 'cuda:0'
  netparams:
    pretrained: false
    num_classes: 10
    initialization: 'kaiming'
    # ResNet18 will infer input size from transforms; CIFAR10 uses 32x32

# Learner (optimizer/loss only matter if epochs_short > 0)
learner:
  type: 'backprop'
  network_class: 'conv'
  init: 'kaiming'
  device: 'cuda:0'
  opt: 'sgd'
  loss: 'cross_entropy'
  step_size: 0.01
  momentum: 0.9
  weight_decay: 0.0
  use_grad_clip: false

# LLA-specific controls
lla:
  training:
    epochs_short: 0
    optimizer: 'sgd'
    lr: 0.01
    weight_decay: 0.0
    save_checkpoints: true
    max_checkpoints: 6      # lower default for heavier models
    second_run_seed: 12345
  evaluation_data:
    eval_batch_size: 64     # smaller to avoid OOM during HVP on ResNet
    dataset_fraction_for_landscape: 1.0
    fixed_eval_seed: 42
  planes:
    enable: true
    grid_resolution: 41
    high_res: false
    span: [-1.0, 1.0]
    normalization: 'filter'
    include_random: true
    include_hessian: true
    include_trajectory: true
    bn:
      eval_mode_only: true
      exclude_bn_and_bias: false  # keep default; can flip to true to reduce dim
    chunk_size: 64
    max_eval_points_cap: 4096
  spectrum:
    enable: true
    top_k: 5
    hutchinson_probes: 6
    esd:
      num_probes: 6
      lanczos_steps: 30
      bins: 80
  sam:
    enable: true
    rho: 0.05
    subsample_stride: 4    # subsample grid for tractability on ResNet
  mode_connectivity:
    enable: true
    curve_points: 21
    opt_steps: 60          # reduce for demo timing
    lr: 0.05
    use_second_run: true
    data_subset_batches: 1

# Rank tracking (top-level)
rank_tracking:
  enable: true
  batch_size: 128
  approximate_rank_prop: 0.99
  compute_gini: true

# Runtime (top-level)
runtime:
  device: 'cuda:0'
  fp16: false
  workers: 2
  pbar: true
  abort_if_estimated_hours_over: null

# Logging (top-level)
logging:
  out_root: 'experiments/Hessian_and_landscape_plot_with_plasticity_loss/results_resnet'
  save_numpy: true
  save_csv: true
  wandb: false
