{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Basic Reinforcement Learning Experiment\n",
    "\n",
    "This notebook provides a step-by-step guide to running the basic reinforcement learning (RL) experiment in this repository. The experiment uses the `CartPole-v1` environment from `gymnasium` and the PPO algorithm from `stable-baselines3`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Understanding the Configuration\n",
    "\n",
    "The configuration for this experiment is defined in `cfg/config.yaml`. Let's take a look at its contents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat cfg/config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The configuration file is split into several sections:\n",
    "- **General settings**: `seed`, `device`, `total_timesteps`.\n",
    "- **Environment settings**: `env.id` specifies the `gymnasium` environment to use.\n",
    "- **Learner settings**: `learner.type` specifies the RL algorithm (`ppo`), `learner.policy` is the policy network type, and `learner.model_kwargs` contains the hyperparameters for the `stable-baselines3` model.\n",
    "- **Net settings**: This section is for defining custom policy networks. It's not used in this basic experiment, but it will be used in the `tracking_in_RL` experiment.\n",
    "- **Logging settings**: For logging with `wandb`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Running the Experiment\n",
    "\n",
    "The `train.py` script is the entry point for the experiment. It loads the configuration, creates the environment and the learner, and starts the training.\n",
    "\n",
    "You can run the experiment from the command line, or directly from this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Understanding the Output\n",
    "\n",
    "The script will print the configuration and then start training. `stable-baselines3` provides its own logging output, showing metrics like the episode reward, loss, and other algorithm-specific values.\n",
    "\n",
    "After training, the script will save the trained model to a file called `model.zip` in the `outputs` directory (in a subdirectory created by `hydra`)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
