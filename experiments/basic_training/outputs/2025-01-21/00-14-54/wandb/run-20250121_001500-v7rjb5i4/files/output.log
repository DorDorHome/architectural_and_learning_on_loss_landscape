Epoch: 0, progress on batches: 100%|███| 196/196 [00:15<00:00, 12.92it/s]
Epoch: 1, progress on batches: 100%|███| 196/196 [00:05<00:00, 37.44it/s]
Epoch: 0, Accuracy: 0.24378, Accuracy_2: 0.24378, Loss:,  2.7859716732025146, loss by batch: 2.78265024752033
Epoch: 2, progress on batches: 100%|███| 196/196 [00:05<00:00, 37.47it/s]
Epoch: 1, Accuracy: 0.36514, Accuracy_2: 0.36514, Loss:,  1.7593666146469116, loss by batch: 1.7590685401644026
Epoch: 3, progress on batches: 100%|███| 196/196 [00:05<00:00, 37.58it/s]
Epoch: 2, Accuracy: 0.42662, Accuracy_2: 0.42662, Loss:,  1.6033493880462646, loss by batch: 1.6024549329767421
Epoch: 4, progress on batches: 100%|███| 196/196 [00:05<00:00, 37.63it/s]
Epoch: 3, Accuracy: 0.47136, Accuracy_2: 0.47136, Loss:,  1.4618446933364868, loss by batch: 1.461903151200742
Epoch: 5, progress on batches: 100%|███| 196/196 [00:05<00:00, 37.80it/s]
Epoch: 4, Accuracy: 0.51126, Accuracy_2: 0.51126, Loss:,  1.3656581234741212, loss by batch: 1.3663026976342103
Epoch: 6, progress on batches: 100%|███| 196/196 [00:05<00:00, 37.68it/s]
Epoch: 5, Accuracy: 0.54852, Accuracy_2: 0.54852, Loss:,  1.2625819219207763, loss by batch: 1.2624458530727698
Epoch: 7, progress on batches: 100%|███| 196/196 [00:05<00:00, 37.56it/s]
Epoch: 6, Accuracy: 0.58988, Accuracy_2: 0.58988, Loss:,  1.1501463540458678, loss by batch: 1.149512651623512
Epoch: 8, progress on batches: 100%|███| 196/196 [00:05<00:00, 37.74it/s]
Epoch: 7, Accuracy: 0.61944, Accuracy_2: 0.61944, Loss:,  1.0665472398757934, loss by batch: 1.0668204800814998
Epoch: 9, progress on batches: 100%|███| 196/196 [00:05<00:00, 37.67it/s]
Epoch: 8, Accuracy: 0.6489, Accuracy_2: 0.6489, Loss:,  0.9938758097076416, loss by batch: 0.993982376188648
Epoch: 10, progress on batches: 100%|██| 196/196 [00:05<00:00, 37.65it/s]
Epoch: 9, Accuracy: 0.6701, Accuracy_2: 0.6701, Loss:,  0.9388210247421265, loss by batch: 0.9395181296431289
Epoch: 11, progress on batches: 100%|██| 196/196 [00:05<00:00, 37.73it/s]
Epoch: 10, Accuracy: 0.68236, Accuracy_2: 0.68236, Loss:,  0.9035788221931458, loss by batch: 0.9031772199942141
Epoch: 12, progress on batches: 100%|██| 196/196 [00:05<00:00, 37.74it/s]
Epoch: 11, Accuracy: 0.69972, Accuracy_2: 0.69972, Loss:,  0.8691619680404663, loss by batch: 0.8685626527484582
Epoch: 13, progress on batches: 100%|██| 196/196 [00:05<00:00, 37.74it/s]
Epoch: 12, Accuracy: 0.71138, Accuracy_2: 0.71138, Loss:,  0.841952820930481, loss by batch: 0.8420596873881866
Epoch: 14, progress on batches: 100%|██| 196/196 [00:05<00:00, 37.56it/s]
Epoch: 13, Accuracy: 0.71462, Accuracy_2: 0.71462, Loss:,  0.8338322760391236, loss by batch: 0.8339489990351151
Epoch: 15, progress on batches: 100%|██| 196/196 [00:05<00:00, 37.73it/s]
Epoch: 14, Accuracy: 0.7245, Accuracy_2: 0.7245, Loss:,  0.8127404780960082, loss by batch: 0.8127119002901778
Epoch: 16, progress on batches: 100%|██| 196/196 [00:05<00:00, 37.58it/s]
Epoch: 15, Accuracy: 0.72766, Accuracy_2: 0.72766, Loss:,  0.8033416437149048, loss by batch: 0.8035753092595509
Epoch: 17, progress on batches: 100%|██| 196/196 [00:05<00:00, 37.67it/s]
Epoch: 16, Accuracy: 0.73334, Accuracy_2: 0.73334, Loss:,  0.7869813868713379, loss by batch: 0.7873379697605055
Epoch: 18, progress on batches: 100%|██| 196/196 [00:05<00:00, 37.38it/s]
Epoch: 17, Accuracy: 0.7391, Accuracy_2: 0.7391, Loss:,  0.7705503288650513, loss by batch: 0.771590424131374
Epoch: 19, progress on batches: 100%|██| 196/196 [00:05<00:00, 37.84it/s]
Epoch: 18, Accuracy: 0.74416, Accuracy_2: 0.74416, Loss:,  0.7590834570503235, loss by batch: 0.7592611087828266
Epoch: 20, progress on batches: 100%|██| 196/196 [00:05<00:00, 37.64it/s]
Epoch: 19, Accuracy: 0.7459, Accuracy_2: 0.7459, Loss:,  0.7528372650909424, loss by batch: 0.7521909007004329
Epoch: 21, progress on batches: 100%|██| 196/196 [00:05<00:00, 37.65it/s]
Epoch: 20, Accuracy: 0.75176, Accuracy_2: 0.75176, Loss:,  0.7367415116119385, loss by batch: 0.7377056023296045
Epoch: 22, progress on batches: 100%|██| 196/196 [00:05<00:00, 37.69it/s]
Epoch: 21, Accuracy: 0.75164, Accuracy_2: 0.75164, Loss:,  0.7362617492675781, loss by batch: 0.7358979786537132
Epoch: 23, progress on batches: 100%|██| 196/196 [00:05<00:00, 37.52it/s]
Epoch: 22, Accuracy: 0.75568, Accuracy_2: 0.75568, Loss:,  0.7253904028701782, loss by batch: 0.7256347120416408
Epoch: 24, progress on batches: 100%|██| 196/196 [00:05<00:00, 37.59it/s]
Epoch: 23, Accuracy: 0.7586, Accuracy_2: 0.7586, Loss:,  0.7160668251419068, loss by batch: 0.7159238250888124
Epoch: 25, progress on batches: 100%|██| 196/196 [00:05<00:00, 37.66it/s]
Epoch: 24, Accuracy: 0.75842, Accuracy_2: 0.75842, Loss:,  0.7196528924942016, loss by batch: 0.7195941878824818
Epoch: 26, progress on batches: 100%|██| 196/196 [00:05<00:00, 37.62it/s]
Epoch: 25, Accuracy: 0.76422, Accuracy_2: 0.76422, Loss:,  0.7037611617469788, loss by batch: 0.7039113543471511
Epoch: 27, progress on batches: 100%|██| 196/196 [00:05<00:00, 37.61it/s]
Epoch: 26, Accuracy: 0.76206, Accuracy_2: 0.76206, Loss:,  0.7103413140487671, loss by batch: 0.710522325671449
Epoch: 28, progress on batches: 100%|██| 196/196 [00:05<00:00, 37.78it/s]
Epoch: 27, Accuracy: 0.76264, Accuracy_2: 0.76264, Loss:,  0.7031793364715576, loss by batch: 0.7027422940852691
Epoch: 29, progress on batches: 100%|██| 196/196 [00:05<00:00, 37.79it/s]
Epoch: 28, Accuracy: 0.7651, Accuracy_2: 0.7651, Loss:,  0.6945480047416687, loss by batch: 0.6951525495672712
Epoch: 30, progress on batches: 100%|██| 196/196 [00:05<00:00, 37.78it/s]
Epoch: 29, Accuracy: 0.7683, Accuracy_2: 0.7683, Loss:,  0.6905758014106751, loss by batch: 0.6912399278003343
Epoch: 31, progress on batches: 100%|██| 196/196 [00:05<00:00, 37.61it/s]
Epoch: 30, Accuracy: 0.76994, Accuracy_2: 0.76994, Loss:,  0.6867479700088501, loss by batch: 0.6861482438992481
Epoch: 32, progress on batches: 100%|██| 196/196 [00:05<00:00, 37.84it/s]
Epoch: 31, Accuracy: 0.7691, Accuracy_2: 0.7691, Loss:,  0.6831427021598816, loss by batch: 0.6840538853893474
Epoch: 33, progress on batches: 100%|██| 196/196 [00:05<00:00, 37.61it/s]
Epoch: 32, Accuracy: 0.77058, Accuracy_2: 0.77058, Loss:,  0.6859048100471496, loss by batch: 0.6855908300803633
Epoch: 34, progress on batches: 100%|██| 196/196 [00:05<00:00, 37.43it/s]
Epoch: 33, Accuracy: 0.7735, Accuracy_2: 0.7735, Loss:,  0.677643855419159, loss by batch: 0.6774725819728813
Epoch: 35, progress on batches: 100%|██| 196/196 [00:05<00:00, 37.64it/s]
Epoch: 34, Accuracy: 0.77056, Accuracy_2: 0.77056, Loss:,  0.6817110360527039, loss by batch: 0.6817470746380943
Epoch: 36, progress on batches: 100%|██| 196/196 [00:05<00:00, 37.46it/s]
Epoch: 35, Accuracy: 0.7759, Accuracy_2: 0.7759, Loss:,  0.669534108467102, loss by batch: 0.6696099908072122
Epoch: 37, progress on batches: 100%|██| 196/196 [00:05<00:00, 37.65it/s]
Epoch: 36, Accuracy: 0.77272, Accuracy_2: 0.77272, Loss:,  0.6776660667037964, loss by batch: 0.6778244884038458
Epoch: 38, progress on batches: 100%|██| 196/196 [00:05<00:00, 37.73it/s]
Epoch: 37, Accuracy: 0.77818, Accuracy_2: 0.77818, Loss:,  0.6634355867385864, loss by batch: 0.6642238064383974
Epoch: 39, progress on batches: 100%|██| 196/196 [00:05<00:00, 37.53it/s]
Epoch: 38, Accuracy: 0.7761, Accuracy_2: 0.7761, Loss:,  0.6696638879203797, loss by batch: 0.6704310405315185
Epoch: 40, progress on batches: 100%|██| 196/196 [00:05<00:00, 37.74it/s]
Epoch: 39, Accuracy: 0.77468, Accuracy_2: 0.77468, Loss:,  0.6699285265922547, loss by batch: 0.6699081954299188
Epoch: 41, progress on batches: 100%|██| 196/196 [00:05<00:00, 37.79it/s]
Epoch: 40, Accuracy: 0.77442, Accuracy_2: 0.77442, Loss:,  0.6730401558876038, loss by batch: 0.6732002712634145
Epoch: 42, progress on batches: 100%|██| 196/196 [00:05<00:00, 37.74it/s]
Epoch: 41, Accuracy: 0.77926, Accuracy_2: 0.77926, Loss:,  0.6603688983726501, loss by batch: 0.6600579807952959
Epoch: 43, progress on batches: 100%|██| 196/196 [00:05<00:00, 37.44it/s]
Epoch: 42, Accuracy: 0.77916, Accuracy_2: 0.77916, Loss:,  0.6610524991607666, loss by batch: 0.6611726052907049
Epoch: 44, progress on batches: 100%|██| 196/196 [00:05<00:00, 37.47it/s]
Epoch: 43, Accuracy: 0.77894, Accuracy_2: 0.77894, Loss:,  0.6607129211997986, loss by batch: 0.6604631255779948
Epoch: 45, progress on batches: 100%|██| 196/196 [00:05<00:00, 37.56it/s]
Epoch: 44, Accuracy: 0.77932, Accuracy_2: 0.77932, Loss:,  0.6542816564559937, loss by batch: 0.654329946606743
Epoch: 46, progress on batches: 100%|██| 196/196 [00:05<00:00, 37.70it/s]
Epoch: 45, Accuracy: 0.77984, Accuracy_2: 0.77984, Loss:,  0.6616650956535339, loss by batch: 0.6619315594434738
Epoch: 47, progress on batches: 100%|██| 196/196 [00:05<00:00, 37.58it/s]
Epoch: 46, Accuracy: 0.78314, Accuracy_2: 0.78314, Loss:,  0.6529984468650818, loss by batch: 0.653052536200504
Epoch: 48, progress on batches:  64%|█▎| 126/196 [00:03<00:01, 36.81it/s]
Epoch: 47, Accuracy: 0.78164, Accuracy_2: 0.78164, Loss:,  0.6540834805679321, loss by batch: 0.654107580379564
Epoch:   5%|█▏                       | 48/1000 [04:23<1:27:03,  5.49s/it]
Traceback (most recent call last):
  File "/home/sfchan/models/architectural_and_learning_on_loss_landscape/experiments/basic_training/single_run.py", line 199, in <module>
    main()
  File "/home/sfchan/anaconda3/envs/loss_landscape/lib/python3.9/site-packages/hydra/main.py", line 94, in decorated_main
    _run_hydra(
  File "/home/sfchan/anaconda3/envs/loss_landscape/lib/python3.9/site-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
  File "/home/sfchan/anaconda3/envs/loss_landscape/lib/python3.9/site-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
  File "/home/sfchan/anaconda3/envs/loss_landscape/lib/python3.9/site-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
  File "/home/sfchan/anaconda3/envs/loss_landscape/lib/python3.9/site-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
  File "/home/sfchan/anaconda3/envs/loss_landscape/lib/python3.9/site-packages/hydra/_internal/hydra.py", line 119, in run
    ret = run_job(
  File "/home/sfchan/anaconda3/envs/loss_landscape/lib/python3.9/site-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
  File "/home/sfchan/models/architectural_and_learning_on_loss_landscape/experiments/basic_training/single_run.py", line 164, in main
    loss, output = learner.learn(input, label)
  File "/home/sfchan/models/architectural_and_learning_on_loss_landscape/src/algos/supervised/basic_backprop.py", line 46, in learn
    return loss.item(), output.detach()
KeyboardInterrupt
