2025-07-19 02:55:39,561 INFO    MainThread:2461760 [wandb_setup.py:_flush():79] Current SDK version is 0.18.5
2025-07-19 02:55:39,561 INFO    MainThread:2461760 [wandb_setup.py:_flush():79] Configure stats pid to 2461760
2025-07-19 02:55:39,561 INFO    MainThread:2461760 [wandb_setup.py:_flush():79] Loading settings from /home/sfchan/.config/wandb/settings
2025-07-19 02:55:39,561 INFO    MainThread:2461760 [wandb_setup.py:_flush():79] Loading settings from /hdda/models/my_own_models/architectural_and_learning_on_loss_landscape/experiments/output_vs_input_plasticity/wandb/settings
2025-07-19 02:55:39,561 INFO    MainThread:2461760 [wandb_setup.py:_flush():79] Loading settings from environment variables: {}
2025-07-19 02:55:39,561 INFO    MainThread:2461760 [wandb_setup.py:_flush():79] Applying setup settings: {'mode': None, '_disable_service': None}
2025-07-19 02:55:39,561 INFO    MainThread:2461760 [wandb_setup.py:_flush():79] Inferring run settings from compute environment: {'program_relpath': 'experiments/output_vs_input_plasticity/train_data_shift_mode.py', 'program_abspath': '/hdda/models/my_own_models/architectural_and_learning_on_loss_landscape/experiments/output_vs_input_plasticity/train_data_shift_mode.py', 'program': '/hdda/models/my_own_models/architectural_and_learning_on_loss_landscape/experiments/output_vs_input_plasticity/train_data_shift_mode.py'}
2025-07-19 02:55:39,561 INFO    MainThread:2461760 [wandb_setup.py:_flush():79] Applying login settings: {}
2025-07-19 02:55:39,561 INFO    MainThread:2461760 [wandb_init.py:_log_setup():534] Logging user logs to /hdda/models/my_own_models/architectural_and_learning_on_loss_landscape/experiments/output_vs_input_plasticity/wandb/run-20250719_025539-80knw3wc/logs/debug.log
2025-07-19 02:55:39,561 INFO    MainThread:2461760 [wandb_init.py:_log_setup():535] Logging internal logs to /hdda/models/my_own_models/architectural_and_learning_on_loss_landscape/experiments/output_vs_input_plasticity/wandb/run-20250719_025539-80knw3wc/logs/debug-internal.log
2025-07-19 02:55:39,561 INFO    MainThread:2461760 [wandb_init.py:init():621] calling init triggers
2025-07-19 02:55:39,561 INFO    MainThread:2461760 [wandb_init.py:init():628] wandb.init called with sweep_config: {}
config: {'runs': 1, 'run_id': 0, 'seed': 492754215, 'device': 'cuda:1', 'epochs': 50, 'batch_size': 256, 'num_tasks': 4000, 'task_shift_mode': 'output_permutation', 'debug_mode': False, 'track_rank': True, 'track_rank_batch': 'use_specified', 'specified_batch_size': 1000, 'rank_measure_freq_to_epoch': 1, 'use_pytorch_entropy_for_effective_rank': True, 'prop_for_approx_or_l1_rank': 0.99, 'numerical_rank_epsilon': 0.01, 'track_dead_units': True, 'threshold_for_non_saturating_act': 0.01, 'track_actual_rank': True, 'track_weight_magnitude': True, 'layers_identifier': None, 'use_wandb': True, 'use_json': False, 'wandb': {'project': 'input_vs_output_shift_with_rank_tracking', 'entity': ''}, 'data': {'dataset': 'MNIST', 'use_torchvision': True, 'data_path': '/hdda/datasets', 'num_classes': 10}, 'net': {'type': 'ConvNet_FC_layer_norm', 'network_class': 'conv', 'device': 'cuda:1', 'netparams': {'pretrained': False, 'num_classes': 10, 'initialization': 'kaiming', 'input_height': 28, 'input_width': 28, 'conv_layer_bias': True, 'linear_layer_bias': True, 'activation': 'leaky_relu', 'norm_param': {'layer_norm': {'eps': 1e-05, 'elementwise_affine': False}}, 'weight_correction_scale': 1.0, 'fan_in_correction': False, 'SVD_only_stride_1': False, 'allow_svd_values_negative': True, 'num_hidden_layers': 1}}, 'learner': {'type': 'backprop', 'init': 'kaiming', 'device': 'cuda:1', 'opt': 'sgd', 'loss': 'cross_entropy', 'step_size': 0.01, 'beta_1': 0.95, 'beta_2': 0.999, 'weight_decay': 0.01, 'to_perturb': False, 'perturb_scale': 0.05, 'momentum': 0.9}, 'evaluation': {'use_testset': False, 'eval_freq_epoch': 1, 'eval_metrics': ['accuracy', 'loss']}}
2025-07-19 02:55:39,561 INFO    MainThread:2461760 [wandb_init.py:init():671] starting backend
2025-07-19 02:55:39,562 INFO    MainThread:2461760 [wandb_init.py:init():675] sending inform_init request
2025-07-19 02:55:39,563 INFO    MainThread:2461760 [backend.py:_multiprocessing_setup():104] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2025-07-19 02:55:39,564 INFO    MainThread:2461760 [wandb_init.py:init():688] backend started and connected
2025-07-19 02:55:39,567 INFO    MainThread:2461760 [wandb_init.py:init():783] updated telemetry
2025-07-19 02:55:39,665 INFO    MainThread:2461760 [wandb_init.py:init():816] communicating run to backend with 90.0 second timeout
2025-07-19 02:55:40,139 INFO    MainThread:2461760 [wandb_init.py:init():867] starting run threads in backend
2025-07-19 02:55:40,385 INFO    MainThread:2461760 [wandb_run.py:_console_start():2463] atexit reg
2025-07-19 02:55:40,385 INFO    MainThread:2461760 [wandb_run.py:_redirect():2311] redirect: wrap_raw
2025-07-19 02:55:40,385 INFO    MainThread:2461760 [wandb_run.py:_redirect():2376] Wrapping output streams.
2025-07-19 02:55:40,386 INFO    MainThread:2461760 [wandb_run.py:_redirect():2401] Redirects installed.
2025-07-19 02:55:40,388 INFO    MainThread:2461760 [wandb_init.py:init():911] run started, returning control to user process
2025-07-19 02:55:40,600 WARNING MsgRouterThr:2461760 [router.py:message_loop():77] message_loop has been closed
