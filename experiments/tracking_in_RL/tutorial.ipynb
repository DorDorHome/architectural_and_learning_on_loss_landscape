{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Tracking in Reinforcement Learning\n",
    "\n",
    "This notebook explains the `tracking_in_RL` experiment. This experiment demonstrates how to use a custom model architecture as a backbone for an RL agent and how to track metrics like the rank of the feature maps during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The Configuration\n",
    "\n",
    "The configuration in `cfg/config.yaml` is set up for a more complex task (`BipedalWalker-v3`) and enables custom features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat cfg/config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key differences from the basic experiment:\n",
    "- **`env.id`**: Set to `BipedalWalker-v3`, a more challenging environment.\n",
    "- **`learner.policy`**: Set to `MlpPolicy`. We will provide a custom feature extractor to this policy.\n",
    "- **`net` section**: This section is now used to define the custom backbone. `net.type` is set to `rl_mlp_backbone`, which is a custom feature extractor defined in `src/models/rl_backbones.py`. `net.netparams` contains the hyperparameters for this backbone, like `features_dim`.\n",
    "- **`tracking` section**: This section is enabled. `track_rank_freq` controls how often the rank of the features is computed and logged.\n",
    "- **`logging.use_wandb`**: Set to `True` to log the results to Weights & Biases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Custom Backbone and Tracking\n",
    "\n",
    "The `train.py` script contains two key features:\n",
    "\n",
    "### Custom Backbone\n",
    "The script checks if a `net` configuration is present. If so, it uses the `model_factory` to get the specified feature extractor class (`rl_mlp_backbone` in this case). It then constructs a `policy_kwargs` dictionary that tells `stable-baselines3` to use this class for feature extraction. This allows you to experiment with different backbone architectures by simply changing the configuration.\n",
    "\n",
    "### Rank Tracking\n",
    "A custom callback, `RankTrackingCallback`, is defined in the script. This callback is triggered periodically during training. It extracts the feature tensor from the policy's backbone, computes various rank metrics using functions from `src/utils/zeroth_order_features.py`, and logs these metrics to `wandb`. This allows you to monitor the internal dynamics of the network during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Running the Experiment\n",
    "\n",
    "To run this experiment, you need to have a `wandb` account and be logged in. You can run the `train.py` script from the command line or from this notebook.\n",
    "\n",
    "**Note**: This experiment runs for more timesteps and can take some time to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure to log in to wandb first if you haven't already\n",
    "# import wandb\n",
    "# wandb.login()\n",
    "\n",
    "!python train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Viewing the Results\n",
    "\n",
    "After running the experiment, you can go to your `wandb` project to see the results. You will find the standard RL metrics (reward, loss, etc.) as well as the custom rank metrics that were logged by the `RankTrackingCallback`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
