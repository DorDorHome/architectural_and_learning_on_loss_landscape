2025-01-08 21:21:15,787 INFO    MainThread:1691232 [wandb_setup.py:_flush():79] Current SDK version is 0.18.5
2025-01-08 21:21:15,787 INFO    MainThread:1691232 [wandb_setup.py:_flush():79] Configure stats pid to 1691232
2025-01-08 21:21:15,787 INFO    MainThread:1691232 [wandb_setup.py:_flush():79] Loading settings from /home/sfchan/.config/wandb/settings
2025-01-08 21:21:15,787 INFO    MainThread:1691232 [wandb_setup.py:_flush():79] Loading settings from /hdda/models/my_own_models/architectural_and_learning_on_loss_landscape/outputs/2025-01-08/21-21-11/wandb/settings
2025-01-08 21:21:15,787 INFO    MainThread:1691232 [wandb_setup.py:_flush():79] Loading settings from environment variables: {}
2025-01-08 21:21:15,788 INFO    MainThread:1691232 [wandb_setup.py:_flush():79] Applying setup settings: {'mode': None, '_disable_service': None}
2025-01-08 21:21:15,788 INFO    MainThread:1691232 [wandb_setup.py:_flush():79] Inferring run settings from compute environment: {'program_relpath': 'experiments/basic_training/single_loss_gradient_expr.py', 'program_abspath': '/hdda/models/my_own_models/architectural_and_learning_on_loss_landscape/experiments/basic_training/single_loss_gradient_expr.py', 'program': '/hdda/models/my_own_models/architectural_and_learning_on_loss_landscape/experiments/basic_training/single_loss_gradient_expr.py'}
2025-01-08 21:21:15,788 INFO    MainThread:1691232 [wandb_setup.py:_flush():79] Applying login settings: {}
2025-01-08 21:21:15,788 INFO    MainThread:1691232 [wandb_init.py:_log_setup():534] Logging user logs to /hdda/models/my_own_models/architectural_and_learning_on_loss_landscape/outputs/2025-01-08/21-21-11/wandb/run-20250108_212115-9wdbihuz/logs/debug.log
2025-01-08 21:21:15,788 INFO    MainThread:1691232 [wandb_init.py:_log_setup():535] Logging internal logs to /hdda/models/my_own_models/architectural_and_learning_on_loss_landscape/outputs/2025-01-08/21-21-11/wandb/run-20250108_212115-9wdbihuz/logs/debug-internal.log
2025-01-08 21:21:15,788 INFO    MainThread:1691232 [wandb_init.py:init():621] calling init triggers
2025-01-08 21:21:15,789 INFO    MainThread:1691232 [wandb_init.py:init():628] wandb.init called with sweep_config: {}
config: {'use_wandb': True, 'runs': 1, 'seed': 42, 'device': 'cuda', 'epochs': 10, 'batch_size': 128, 'data': {'dataset': 'CIFAR10', 'data_path': '/hdda/datasets', 'num_classes': 10}, 'net': {'type': 'ConvNet', 'netparams': {'num_classes': 10}}, 'learner': {'type': 'backprop', 'device': 'cuda', 'opt': 'adam', 'loss': 'nll', 'step_size': 0.01, 'beta_1': 0.95, 'beta_2': 0.999, 'weight_decay': 0.01, 'to_perturb': False, 'perturb_scale': 0.05, 'momentum': 0.9}, 'evaluation': {'eval_freq_epoch': 1, 'eval_metrics': ['accuracy', 'loss'], 'save_dir': '/results/results_raw'}}
2025-01-08 21:21:15,789 INFO    MainThread:1691232 [wandb_init.py:init():671] starting backend
2025-01-08 21:21:15,789 INFO    MainThread:1691232 [wandb_init.py:init():675] sending inform_init request
2025-01-08 21:21:15,793 INFO    MainThread:1691232 [backend.py:_multiprocessing_setup():104] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2025-01-08 21:21:15,795 INFO    MainThread:1691232 [wandb_init.py:init():688] backend started and connected
2025-01-08 21:21:15,804 INFO    MainThread:1691232 [wandb_init.py:init():783] updated telemetry
2025-01-08 21:21:15,895 INFO    MainThread:1691232 [wandb_init.py:init():816] communicating run to backend with 90.0 second timeout
2025-01-08 21:21:16,461 INFO    MainThread:1691232 [wandb_init.py:init():867] starting run threads in backend
2025-01-08 21:21:16,678 INFO    MainThread:1691232 [wandb_run.py:_console_start():2463] atexit reg
2025-01-08 21:21:16,678 INFO    MainThread:1691232 [wandb_run.py:_redirect():2311] redirect: wrap_raw
2025-01-08 21:21:16,678 INFO    MainThread:1691232 [wandb_run.py:_redirect():2376] Wrapping output streams.
2025-01-08 21:21:16,678 INFO    MainThread:1691232 [wandb_run.py:_redirect():2401] Redirects installed.
2025-01-08 21:21:16,680 INFO    MainThread:1691232 [wandb_init.py:init():911] run started, returning control to user process
